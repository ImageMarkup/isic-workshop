<!DOCTYPE html>
<html>
<head>
<!-- saved from url=(0038)https://workshop2021.isic-archive.com/ -->







  
  
  
  
  
  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- saved from url=(0038)https://workshop2021.isic-archive.com/ -->







  


  
  
  
  
  
  
  
  
  
  
  
  <title>ISIC Skin Image Analysis Workshop @ MICCAI 2025</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->







  
  
  
  
  
  
  <link rel="stylesheet" href="./index_files/main.css">
<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
</head>


<body>







<footer></footer>
<div id="wrapper">
<div id="main">
<div id="workshop" class="container"> <header class="major"> </header>
<h3><img style="width: 1024px; height: 122px;" alt="ISIC 2025 Workshop Banner" src="./index_files/banner.jpg"></h3>







<h1>[ <a style="color: rgb(51, 51, 255);" href="#intro">Introduction</a>
| <a style="color: rgb(51, 51, 255);" href="#invited_speakers">Invited
Speakers</a> | <a style="color: rgb(51, 51, 255);" href="#dates">Important
Dates</a> | <a style="color: rgb(51, 51, 255);" href="#paper_submission">Paper
Submission</a> | <a style="color: rgb(51, 51, 255);" href="#datasets">Datasets</a>
| <a style="color: rgb(51, 51, 255);" href="#schedule">Program
Schedule</a> | <a style="color: rgb(51, 51, 255);" href="#organizers">Organizers</a>&nbsp;|&nbsp;<a style="color: rgb(51, 51, 255);" href="index.html#pastworkshops">Past
Workshops</a><span style="color: rgb(51, 51, 255);">&nbsp;</span>]</h1>







<b style="color: red;">09/16/2025: Datasets section updated</b><br>


<b style="color: red;">09/04/2025: Datasets section updated</b><br>






<b style="color: red;">09/02/2025: Invited speakers and program schedule updated</b><br>






<b style="color: red;">06/25/2025: Submission deadline
extended and PC updated<br>







04/29/2025: Section on past workshops added<br>







03/26/2025:
Website launched</b><br>







<h3>Tenth
ISIC Skin Image Analysis Workshop<a href="https://conferences.miccai.org/2025/en/"><br>







</a></h3>







<h3>@ <span style="text-decoration: underline;"></span><a href="https://conferences.miccai.org/2025/en/">MICCAI 2025</a></h3>







<h3><a href="https://conferences.miccai.org/2025/en/">
</a></h3>







<p>Hosted by the <a href="https://www.isic-archive.com/">International
Skin Imaging Collaboration (ISIC)</a></p>







<h3><a name="intro"></a>Introduction</h3>







<a href="https://cmt3.research.microsoft.com/ISICW2025/Submission/Index">
<p>Skin is the largest organ of the human body, and is the first
area of a patient assessed by
clinical staff. The skin delivers numerous insights into a
patient&rsquo;s underlying health: for
example, pale or blue skin suggests
respiratory issues, unusually yellowish skin
can signal hepatic issues, or certain rashes
can be indicative of autoimmune issues.
In addition, dermatological complaints are also among the most
prevalent in primary care (Lowell <span style="font-style: italic;">et
al.</span>, 2001). Images of the skin are the
most easily captured form of medical image in healthcare, and the
domain shares qualities to standard computer vision datasets,
serving as a natural bridge between standard computer vision tasks and
medical applications. However, significant and unique challenges still
exist in this domain. For example, there is remarkable visual
similarity
across disease conditions, and compared to other
medical imaging domains, varying genetics, disease
states, imaging equipment, and imaging conditions can
significantly change the appearance of the skin, making
localization and classification in this domain unsolved
tasks.
</p>







<p>This workshop will serve as a venue to facilitate advancements
and knowledge dissemination in the field of skin image analysis,
raising awareness and interest for these socially valuable tasks.
Invited speakers include major influencers in computer
vision and skin imaging, and authors of accepted papers.</p>







<p>Lowell <span style="font-style: italic;">et
al.</span> &ldquo;Dermatology in Primary Care:
Prevalence and Patient Disposition,&rdquo; Journal of the American
Academy
of Dermatology, vol. 45, no. 2, pp. 250&ndash;255, 2001.</p>







<h4>Topics of interest include:</h4>







<ul>







</ul>







</a>
<ul>







  <li>Computer
Vision in Dermatology and Primary Care</li>







  <li>Few-Shot
Learning for Dermatological Conditions</li>







  <li>Skin
Analysis from Dermoscopic Images</li>







  <li>Skin
Analysis from Clinical Photographs</li>







  <li>Skin
Analysis from Video</li>







  <li>Skin
Analysis from Total-Body Photography and 3D Skin Reconstructions</li>







  <li>Skin
Analysis from Confocal Microscopy</li>







  <li>Skin
Analysis from Optical Coherence Tomography (OCT)</li>







  <li>Skin
Analysis from Histopathological Images</li>







  <li>Skin
Analysis from ex-vivo and Fluorescence Microscopy</li>







  <li>Skin
Analysis from Multi-Modal Data Sources</li>







  <li>Explainable
Artificial Intelligence (XAI) Related to Skin Image Analysis</li>







  <li>Algorithms
to Mitigate Class Imbalance</li>







  <li>Uncertainty
Estimation Related to Skin Image Analysis</li>







  <li>Human-Computer
Interaction &amp; Application Workflows for Skin Image Analysis</li>







  <li>Robustness
to Bias from Clinical and User-Originating Photography</li>







  <li>Assessing
and Creating Fairness of Skin Analysis in Underrepresented
Groups&nbsp;</li>







  <li>Combined Application of Image Analysis and Large Language
Models/Natural Language Processing&nbsp;(<span style="font-style: italic;">e.g.</span>, applied to
EHR)</li>







  <li>Skin Cancer Prognosis and/or Risk Stratification Using Skin
Imaging Data
    
    
    
    
    
    
    <ul>







    
    
    
    
    
    
    </ul>







  </li>







</ul>







<a href="https://cmt3.research.microsoft.com/ISICW2025/Submission/Index"><b>The
workshop will give out two awards towards paper submissions:</b>
<ul style="padding-top: 0px;">







  <li style="padding-top: 0px;">Best Paper Award&nbsp;</li>







  <li>Honorable Mention Award</li>







</ul>







</a>Judging will be carried out by the workshop chairs based on
the&nbsp;reviewer comments,
novelty, potential impact, and manuscript quality.<br>







<br>







</div>







<section id="speakers"> </section>
<div class="container">
<h3><a name="invited_speakers"></a>Invited
Speakers</h3>







<p>The workshop will feature several prominent names in the
field of skin image analysis, including:</p>







<div class="table-wrapper">
<table>







  <tbody>







    <tr>







      <td width="30%">
      
      
      
      
      
      
      <center><a style="font-weight: bold;" href="https://zongyuange.github.io/">Zongyuan Ge</a><br>







      <img style="width: 200px; height: 200px;" alt="Zongyuan Ge" src="index_files/zongyuan_ge.jpg"></center>







      </td>







      <td style="vertical-align: middle;" valign="center" width="80%">Associate Professor <span style="font-weight: bold;">Zongyuan Ge</span>
conducts interdisciplinary research at the boundary between Medical
Artificial Intelligence, Computer-aided Diagnosis, Biomedical
Engineering, Digital Health, Medical Imaging and Machine Learning and
is a multi-award-winning medical information science and technology
entrepreneur. His research leverages cutting-edge AI technologies using
large-scale multi-modality medical data including imaging, biological
signal, medical records, genomics data, multi-omics and models the
clinicians&rsquo; medical knowledge underlying tasks like
diagnosis,
prognosis, disease management and treatment for eye (ophthalmology),
skin (dermatology), heart (cardiovascular) and neurodegeneration
diseases such as epilepsy, dementia and multiple sclerosis.<span style="font-weight: bold;"> </span> </td>







    </tr>







    <tr>







      <td width="30%">
      
      
      
      
      
      
      <center><a style="font-weight: bold;" href="https://www.mskcc.org/research-areas/labs/members/nicholas-kurtansky"><span style="font-weight: bold;">Nicholas R Kurtansky</span></a><br>







      <img style="width: 200px; height: 200px;" alt="Nicholas R Kurtansky" src="index_files/nicholas_r_kurtansky.jpg"></center>







      </td>







      <td style="vertical-align: middle;" valign="center" width="80%"><span style="font-weight: bold;">Nicholas
R Kurtansky </span>is
an administrator of the ISIC Archive and a researcher at Memorial Sloan
Kettering. He led the planning, execution, and reporting of both the
ISIC 2020 and 2024 Grand Challenges, and has played a central role in
feature implementation and dataset curation for the past six years.
With an academic background in statistics and public health, he
currently works as a Senior Data Analyst in the Dermatology Service.
His research in melanoma covers the assessment of risk-prediction
models and clinically-deployed decision support tools as well as
epidemiology, lesion morphology, and disease management. </td>







    </tr>







  
  
  
  
  
  
  </tbody>
</table>







<ul>







</ul>







<section id="dates"> </section>
<div class="container">
<h3><a name="dates"></a>Important Dates</h3>







<div class="table-wrapper">
<table>







  <tbody>







    <tr>







      <td width="30%"><b><font color="red">July
9, 2025:</font></b></td>







      <td width="80%">Paper Submission Deadline
(23:59 Pacific&nbsp;Time)</td>







    </tr>







    <tr>







      <td width="30%"><b>July 29, 2025:</b></td>







      <td width="80%">Author Notifications</td>







    </tr>







    <tr>







      <td width="30%"><b>July 31, 2025:</b></td>







      <td width="80%">Camera-Ready Submission
Deadline&nbsp;(23:59&nbsp;Pacific&nbsp;Time)</td>







    </tr>







    <tr>







      <td style="color: rgb(153, 153, 153);" width="30%"><span style="font-weight: bold; color: rgb(255, 0, 0);">September
23, 2025</span><b>:</b></td>







      <td width="80%"><span style="color: rgb(255, 0, 0); font-weight: bold;">In-Person</span>
Workshop&nbsp;@ MICCAI 2025 (13:30-18:00 Korean Standard Time)</td>







    </tr>







  
  
  
  
  
  
  </tbody>
</table>







</div>







</div>







<section id="paper"> </section>
<div class="container">
<h3><a name="paper_submission"></a>Paper
Submission</h3>







<p>For paper submissions, the <a href="https://conferences.miccai.org/2025/en/PAPER-SUBMISSION-GUIDELINES.html">conference
guidelines</a> are followed (<span style="font-weight: bold;">double-blind</span>
review process, up to 8 pages of text, figures, and tables
+ up to 2
pages of references).
Accepted papers will be published in a<a href="https://www.springer.com/gp/computer-science/lncs">
Lecture Notes in Computer Science (LNCS)</a> volume to be
published by <a href="https://www.springernature.com/gp">Springer
Nature</a>.</p>







<p>The <a href="https://cmt3.research.microsoft.com/">Microsoft
CMT service</a>
will be used for managing the peer-reviewing process for this workshop.
This service was provided for free by Microsoft and they bore all
expenses, including costs for Azure cloud services as well as for
software development and support.
</p>







<p> <a href="https://cmt3.research.microsoft.com/ISICW2025/Submission/Index"><b>Manuscript
Submission System</b></a></p>







</div>







<section id="datasets"> </section>
<div class="container">
<h3><a name="datasets"></a>Public Datasets for
Skin Image Analysis Research</h3>







<ul>







  <li style="padding-bottom: 16px;"><a href="https://github.com/jeremykawahara/derm7pt"><b>Derm7pt</b></a><span style="font-weight: bold;">:</span> Over 2,000
dermoscopic and clinical images of skin lesions
with&nbsp;7-point checklist criteria&nbsp; and diagnostic
category information.</li>







  <li style="padding-bottom: 16px;"><a href="https://licensing.edinburgh-innovations.ed.ac.uk/i/software/dermofit-image-library.html"><b>Dermofit
Image Library</b></a><span style="font-weight: bold;">:</span>
1,300 clinical images of skin lesions with
diagnostic category information and segmentation masks.</li>







  <li style="padding-bottom: 16px;"><a style="font-weight: bold;" href="https://ddi-dataset.github.io/index.html">Diverse
Dermatology Images</a>: 656 clinical images of skin lesions with
diverse skin tone&nbsp; representation and&nbsp;diagnostic
category information.</li>


  <li style="padding-bottom: 16px;"><a href="https://api.isic-archive.com/collections/399/"><span style="font-weight: bold;">DERM12345</span></a>:<span style="font-weight: bold;"> </span>12,345 high-resolution dermatoscopic images with 5 super classes, 15 main classes, and 40 subclasses.</li>







  <li style="padding-bottom: 16px;"><a href="https://github.com/mattgroh/fitzpatrick17k"><b>Fitzpatrick
17k</b></a><span style="font-weight: bold;">:</span>&nbsp;16,577
clinical images with skin condition labels and skin type labels based
on the Fitzpatrick scoring system.</li>







  <li style="padding-bottom: 16px;"><a style="font-weight: bold;" href="https://api.isic-archive.com/collections/251/?page=54">HIBA
Skin Lesions Dataset</a>:
1,616 skin lesion images (1,270 dermoscopy and 346 clinical) acquired
at the Department of Dermatology of Hospital Italiano de Buenos Aires
(HIBA) in Argentina.</li>







  <li style="padding-bottom: 16px;"><a href="http://challenge2018.isic-archive.com/"><b><font color="red">ISIC 2018</font></b></a>
/&nbsp;<b><font><a href="http://challenge2019.isic-archive.com/"><b><font color="red">ISIC 2019</font></b></a></font></b>
/&nbsp;<a href="http://challenge2020.isic-archive.com/"><span style="font-weight: bold;"></span></a><b><font><b><font><a href="http://challenge2020.isic-archive.com/"><b><font color="red">ISIC 2020</font></b></a></font></b></font></b><span style="font-weight: bold;">:</span>
The ISIC has organized the world&rsquo;s
largest repository of dermoscopic images of skin (157,000+ images,
69,000+ of which are publicly available)
to support research and development of methods for segmentation,
feature extraction, and classification. These
datasets are snapshots used for the 2018, 2019, and 2020 ISIC melanoma
detection challenges. See also the <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T">HAM10000</a>
and <a href="https://arxiv.org/abs/1908.02288">BCN20000</a>
datasets.</li>







  <li style="padding-bottom: 16px;"><a href="http://challenge2020.isic-archive.com/"><span style="font-weight: bold;"></span></a><b><font><b><font><a href="https://challenge2024.isic-archive.com/"><b><font color="red">ISIC 2024</font></b></a></font></b></font></b><span style="font-weight: bold;">: </span>These
datasets contain 15mm-by-15mm field-of-view cropped images, centered on
distinct lesions, that were extracted from 3D total body photographs
(TBPs). The official training dataset for the ISIC 2024 challenge is
the SLICE-3D Dataset: 400,000 skin lesion image crops extracted from 3D
TBP for skin cancer detection. The official testing dataset contain
tiles from a separate set of patients.</li>







  <li style="padding-bottom: 16px;"><a href="http://www.cs.rug.nl/%7Eimaging/databases/melanoma_naevi/"><b>MED-NODE</b></a><span style="font-weight: bold;">:</span> 170 clinical
images of skin lesions with diagnostic category information.</li>







  <li style="padding-bottom: 16px;"><b><font><b><font><a href="https://challenge.isic-archive.com/landing/milk10k/"><b><font color="red">MILK10k</font></b></a></font></b></font></b><span style="font-weight: bold;">: </span>The
overarching goal of this benchmark is to develop image analysis tools
that classify the diagnosis of skin lesions using the following set of
information for each case: (i) clinical close-up image, (ii)
dermatoscopic image, and (iii) metadata. The training dataset
contains&nbsp;5,240 lesions, and a blind held-out test dataset contains
479 lesions. </li>



  <li style="padding-bottom: 16px;"><a href="https://data.mendeley.com/datasets/zr7vgbcyr2/1"><b>PAD-UFES-20</b></a><span style="font-weight: bold;">:</span>
Over 2,200 clinical images of skin lesions&nbsp;with associated
metadata.</li>







  <li style="padding-bottom: 16px;"><a href="https://www.fc.up.pt/addi/ph2%20database.html"><b>PH2</b></a><span style="font-weight: bold;">:</span>
200 dermoscopic images of melanocytic lesions with detailed
annotation.&nbsp;</li>







  <li style="padding-bottom: 16px;"><span style="font-weight: bold;"><a href="https://github.com/google-research-datasets/scin">SCIN</a>:</span>&nbsp;10,000+
clinical images of skin, nail, or hair conditions with detailed
annotation.&nbsp;For details, visit <a href="https://blog.research.google/2024/03/scin-new-resource-for-representative.html">here</a>.</li>







  <li style="padding-bottom: 16px;"><b><a href="https://github.com/xpwu95/SPBL_Pytorch">SD-128</a>
    </b>/<b> <a href="https://github.com/xpwu95/SPBL_Pytorch">SD-198</a>
    </b>/<b> <a href="https://github.com/xpwu95/SPBL_Pytorch">SD-260</a></b><span style="font-weight: bold;">:</span> 6,584 clinical
photographs covering 128/198/260 distinct skin
disorders.</li>







</ul>







</div>







<section id="schedule"> </section>
<div class="container">
<h3><a name="schedule"></a>Program Schedule
</h3>







<h4>Date/Time: September 23, 13:30-18:00 KST</h4>







<h4>Location: Room DCC1-2F-204,&nbsp;Exhibition Hall 1 (DCC 1),&nbsp;Daejeon Convention Center (Daejeon<span class="LrzXr">, Republic of Korea)</span></h4>







<table>







  <tbody>







    <tr>







      <td width="20%"><b>13:30:</b></td>







      <td width="80%">Opening Remarks&nbsp;<span style="font-style: italic;"></span><i>(</i><i>Kumar
Abhishek</i><i>)&nbsp;</i><b style="color: orange;">[Slides]</b>
      </td>







    </tr>







    <tr>







      <td width="20%"><b>13:34:</b></td>







      <td width="80%">Invited Talk 1<span style="font-style: italic;"></span>: <span style="font-weight: bold;">Scaling Medical AI: Foundation
Models, Clinical Impact, and the MAVERIC Supercomputing Future</span>
      <i>(Zongyuan Ge)</i> <b style="color: orange;">[Slides]</b> </td>







    </tr>







    <tr>







      <td width="20%"><b>14:10:</b></td>







      <td width="80%">Oral Presentation 1<span style="font-style: italic;"></span>:&nbsp;<span style="font-weight: bold;"></span><b>LesionGen:
A Concept-Guided Diffusion Model for Dermatology Image Synthesis.</b>
Jamil Fayyad* (University of Victoria, Canada), Nourhan Bayasi
(University of British Columbia, Canada), Ziyang Yu (University of
Toronto, Canada), and Homayoun Najjaran (University of Victoria,
Canada)
      <b style="color: MediumSeaGreen;">[<a rel="kin" href="paper_fayyad.pdf">Paper</a>]</b>&nbsp;<b style="color: orange;">[<a href="slides_fayyad.pptx">Slides</a>]</b></td>







    </tr>







    <tr>







      <td width="20%"><b>14:34:</b></td>







      <td width="80%">Short Break 1</td>







    </tr>







    <tr>







      <td width="20%"><b>14:42:</b></td>







      <td width="80%">Oral Presentation 2<span style="font-style: italic;"></span>: <span style="font-weight: bold;">Fitzpatrick Thresholding for Skin
Image Segmentation. </span>Duncan Stothers* (University of
British Columbia, Canada), Lia Gracey (University of Texas at Austin,
USA), Carlie Reeves (University of Mississippi Medical Center, USA),
and Sophia Xu (Columbia University, USA) <span></span>
      <b style="color: MediumSeaGreen;">[<a href="paper_stothers.pdf">Paper</a>]</b>&nbsp;<b style="color: orange;">[<a href="slides_stothers.pptx">Slides</a>]</b></td>







    </tr>







    <tr>







      <td width="20%"><b>15:06:</b></td>







      <td width="80%">Oral Presentation 3: <span style="font-weight: bold;">What Can We Learn from
Inter-Annotator Variability in Skin Lesion Segmentation? </span>Kumar
Abhishek* (Simon Fraser University, Canada), Jeremy Kawahara (AIP Labs,
Hungary), and Ghassan Hamarneh (Simon Fraser University, Canada) <b style="color: MediumSeaGreen;">[<a href="paper_abhishek.pdf">Paper</a>]</b> <b style="color: orange;">[<a href="slides_abhishek.pdf">Slides</a>]</b></td>







    </tr>







    <tr>







      <td width="20%"><b>15:30:</b></td>







      <td width="80%">Coffee Break (Location: Exhibition Hall DCC 2)<br>







      </td>







    </tr>







    <tr>







      <td width="20%"><b>16:00:</b></td>







      <td width="80%">Invited Talk 2<span style="font-style: italic;"></span>: <span style="font-weight: bold;">From Principles to Practice:
Managing a Medical Research Data Repository</span> <i>(Nicholas
R Kurtansky)</i>
      <b style="color: orange;">[<a href="slides_kurtansky.pdf">Slides</a>]</b></td>







    </tr>







    <tr>







      <td width="20%"><b>16:36:</b></td>







      <td width="80%">Oral Presentation 4: <span style="font-weight: bold;">Topology-Aware Deep Models for
Skin Lesion Classification. </span>Sayoni Chakraborty
(University of Texas at Dallas, USA), Philmore Koung (University of
Texas at Dallas, USA), and Baris Coskunuzer* (University of Texas at
Dallas, USA)<span style="font-weight: bold;">&nbsp;</span><b style="color: MediumSeaGreen;">[<a href="paper_chakraborty.pdf">Paper</a>]</b> <b style="color: orange;">[<a href="slides_chakraborty.potx">Slides</a>]</b></td>







    </tr>







    <tr>







      <td width="20%"><b>17:00:</b></td>







      <td width="80%">Short Break 2</td>







    </tr>







    <tr>







      <td width="20%"><b>17:08:</b></td>







      <td width="80%">Oral Presentation 5<span style="font-style: italic;"></span>: <span style="font-weight: bold;">Retrieval-Augmented VLMs for
Multimodal Melanoma Diagnosis. </span>Jihyun Moon (Handong
Global University, South Korea) and Charmgil Hong* (Handong Global
University, South Korea) <b style="color: MediumSeaGreen;">[<a href="paper_moon.pdf">Paper</a>]</b>&nbsp;<b style="color: orange;">[<a href="slides_moon.pptx">Slides</a>]</b></td>







    </tr>







    <tr>







      <td width="20%"><b>17:32:</b></td>







      <td width="80%">Oral Presentation 6<span style="font-style: italic;"></span>: <span style="font-weight: bold;">Lightweight Dual-Task Framework
for Semi-Supervised Lesion Segmentation with Knowledge Distillation
from SAM. </span>Xuan-Loc Huynh (Boston University, USA),
Huy-Thach Pham (North Carolina Agricultural and Technical State
University, USA), Thanh-Minh Nguyen (AI Vietnam Research Lab, Vietnam),
Tran Quang Khai Bui (AI Vietnam Research Lab, Vietnam), Tat-Bach Nguyen
(Iowa State University, USA), Quan Nguyen (Posts and Telecommunications
Institute of Technology, Vietnam), Minh Huu Nhat Le (Methodist
Hospital, USA), Phat K. Huynh (North Carolina Agricultural and
Technical State University, USA), and Anh Vu* (University of Houston,
USA) <b style="color: MediumSeaGreen;">[<a href="paper_huynh.pdf">Paper</a>]</b>&nbsp;<b style="color: orange;">[Slides]</b></td>







    </tr>







    <tr>







      <td><b>17:56:</b></td>







      <td><span style="font-style: italic;"></span>Closing
Remarks&nbsp;<span style="font-style: italic;"></span><i>(</i><i>Kumar Abhishek</i><i>)</i> </td>







    </tr>







  
  
  
  
  
  
  </tbody>
</table>







</div>







</div>







<section id="organizers"> </section>
<div class="container">
<h3><a name="organizers"></a>Organizers</h3>







<h4><b>Sponsors:</b></h4>







<ul>







  <li><a href="https://www.canfieldsci.com/"><span style="font-weight: bold;">Canfield Scientific, Inc.</span>&nbsp;</a></li>







</ul>







<h4><b><b>Workshop Organizers:</b></b></h4>







<ul>







  <li><a target="_blank" href="https://faculty.uca.edu/ecelebi/"><b>M. Emre
Celebi, Ph.D.</b></a> (University of Central Arkansas,
Conway, AR, USA)</li>







  <li><a href="https://welcome.isr.tecnico.ulisboa.pt/author/anacatarinafidalgo/"><span style="font-weight: bold;">Catarina
Barata, Ph.D.</span></a> (Instituto Superior
T&eacute;cnico, Lisbon, Portugal)</li>







  <li><a target="_blank" href="https://www.mskcc.org/cancer-care/doctors/allan-halpern"><b>Allan
Halpern, M.D.</b></a> (Memorial Sloan Kettering Cancer
Center, New York City, NY, USA)</li>







  <li><a target="_blank" href="https://www.meduniwien.ac.at/web/en/research/researcher-profiles/researcher-profiles/detail/?res_id=23"><b>Philipp
Tschandl, M.D. Ph.D.</b></a> (Medical University of Vienna,
Vienna, Austria)<span style="font-weight: bold;"></span></li>







  <li><a href="https://www.linkedin.com/in/marc-combalia/"><b>Marc
Combalia, M.Sc.</b></a> (Kenko AI,
Barcelona, Spain)</li>







  <li><a href="https://research.google/people/106267/"><span style="font-weight: bold;">Yuan Liu,
Ph.D.</span></a> (Google, Mountain View, CA, USA)</li>







  <li><a rel="parent" href="https://www.sfu.ca/%7Ekabhishe/"><b>Kumar
Abhishek, M.Sc.</b></a>&nbsp;(Simon Fraser University,
Burnaby, BC, Canada)</li>







  <li><a target="_blank" href="https://home.agh.edu.pl/%7Ejaworek/dokuwiki/doku.php?id=start"><b>Joanna
Jaworek-Korjakowska, Ph.D.</b></a> (AGH University of
Krak&oacute;w, Krakow, Poland)</li>







  <li><a target="_blank" href="https://www.mmu.ac.uk/staff/profile/professor-moi-hoon-yap"><b>Moi
Hoon Yap, Ph.D.</b></a> (Manchester Metropolitan
University,&nbsp;Manchester, England)</li>







</ul>







<h4><b>Steering Committee:</b></h4>







<ul>







  <li><a href="https://www.linkedin.com/public-profile/in/noel-c-f-codella"><span style="font-weight: bold;">Noel C. F.
Codella, Ph.D.</span></a> (Microsoft, Redmond, WA, USA)</li>







  <li><a target="_blank" href="https://www.kitware.com/anthony-hoogs/"><b>Anthony
Hoogs, Ph.D.</b></a> (Kitware, Clifton Park, NY, USA)</li>







  <li><b><a href="https://research.google/people/105698/">Yun
Liu, Ph.D.</a></b> (Google Health, Palo Alto, CA, USA)</li>







  <li><a style="font-weight: bold;" href="https://research.google/people/DaleWebster/">Dale
Webster, Ph.D.</a> (Google Health, Palo Alto, CA, USA)</li>







</ul>







<h4><b><b>Program Committee:</b></b></h4>







<ul>







  <li>Euijoon Ahn, James Cook University, Australia</li>







  <li>Sandra Avila, University of Campinas, Brazil</li>







  <li>Nourhan Bayasi, University of British Columbia, Canada</li>







  <li>Lei Bi,&nbsp;University of Sydney, Australia</li>







  <li>Siyi Du, Imperial College London, England</li>







  <li>Ghassan Hamarneh, Simon Fraser University, Canada</li>







  <li>Jeremy Kawahara, AIP Labs, Hungary</li>







  <li>Jinman Kim, University of Sydney, Australia</li>







  <li>Sinan Kockara, Rice University, USA</li>







  <li>Kivanc Kose, Memorial Sloan Kettering Cancer Center, USA</li>







  <li>Tim K. Lee, University of British Columbia, Canada</li>







  <li>Carlos Santiago, Instituto Superior
T&eacute;cnico,&nbsp;Portugal</li>







  <li>Janet Wang, Tulane University, USA<br>







  </li>







  <li>Yuheng Wang, University of British Columbia, Canada</li>







  <li>Fengying Xie, Beihang University, China</li>







</ul>







<h4>Contact Email:</h4>







<ul class="copyright">







  <li><a href="mailto:workshop@isic-archive.com">workshop@isic-archive.com</a><br>







    <br>







    <section id="pastworkshops"> </section>
    
    
    
    
    
    
    <div class="container">
    
    
    
    
    
    
    <h3><a name="pastworkshops"></a>Past
Workshops</h3>







    </div>







  </li>







  <li><a href="https://workshop.isic-archive.com/2024/">Ninth
ISIC Skin Image Analysis Workshop</a> @ <a href="https://conferences.miccai.org/2024/en/workshops.asp">MICCAI
2024</a>&nbsp;</li>







  <li><a href="https://workshop.isic-archive.com/2023/">Eighth
ISIC Skin Image Analysis Workshop</a> @ <a href="https://conferences.miccai.org/2023/en/workshops.asp">MICCAI
2023</a>&nbsp;</li>







  <li><a href="https://workshop.isic-archive.com/2022/">Seventh
ISIC Skin Image Analysis Workshop</a> @ <a href="https://eccv2022.ecva.net/program/workshop-schedule/">ECCV
2022</a>&nbsp;</li>







  <li><a href="https://workshop.isic-archive.com/2021/">Sixth
ISIC Skin Image Analysis Workshop</a> @ <a href="https://cvpr2021.thecvf.com/workshops-schedule">CVPR
2021</a>&nbsp;</li>







  <li><a href="https://workshop.isic-archive.com/2020/">Fifth
ISIC Skin Image Analysis Workshop</a> @ <a href="https://cvpr2020.thecvf.com/workshops-schedule">CVPR
2020</a>&nbsp;</li>







  <li><a href="https://workshop.isic-archive.com/2019/">Fourth
ISIC Skin Image Analysis Workshop</a> @ <a href="https://cvpr2019.thecvf.com/program/workshops">CVPR
2019</a>&nbsp;</li>







  <li><a href="https://workshop.isic-archive.com/2018">Third
ISIC Skin Image Analysis Workshop</a> @ MICCAI 2018</li>







  <li>Second ISIC Skin Lesion Analysis Towards Melanoma Detection
Workshop @ <a href="https://biomedicalimaging.org/2017/challenges/">ISBI
2017</a>&nbsp;</li>







  <li>First ISIC Skin Lesion Analysis Towards Melanoma Detection
Workshop @ <a href="https://biomedicalimaging.org/2016/?page_id=422">ISBI
2016</a>&nbsp;</li>







</ul>







&copy; 2025, International
Skin Imaging Collaboration
(ISIC). All rights reserved. Design: <a target="_blank" href="http://html5up.net/">HTML5 UP</a>
<ul class="copyright">







  <li>
    
    
    
    
    
    
    <div class="container">
    
    
    
    
    
    
    <script src="./index_files/jquery.html"></script>
    
    
    
    
    
    
    <script src="./index_files/jquery_002.html"></script>
    
    
    
    
    
    
    <script src="./index_files/jquery_003.html"></script>
    
    
    
    
    
    
    <script src="./index_files/main.html"></script></div>







  </li>







</ul>







</div>







</div>







<div id="titleBar"><span class="title"><a href="#">Ninth ISIC
Skin
Image Analysis Workshop</a></span></div>







<div id="titleBar"><span class="title"><a href="#" style="">Ninth
ISIC
Skin Image Analysis Workshop</a></span></div>







</div>







</div>







</body>
</html>
